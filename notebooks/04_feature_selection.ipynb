{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a00821-5182-4ff7-8a77-4655282d4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, RFE\n",
    "from xgboost import XGBClassifier\n",
    "from dataclasses import dataclass\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.mlflow_utils import configure_mlflow, find_latest_run_id_by_experiment_and_stage, get_targets, get_data, load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b8ec5a5-5f7c-4a33-9d40-664d7b014d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630c696b-3f86-41b7-99f9-8d25716e0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureSelectionResult:\n",
    "    selected_features: pd.Index\n",
    "    selection_mask: np.ndarray\n",
    "    method_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cbe296f-47fa-4b48-8317-d641f5c07b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSelector:\n",
    "    \"\"\"Base class for feature selection methods\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.result: FeatureSelectionResult = None\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def log_metrics(self) -> None:\n",
    "        mlflow.log_param(f\"{self.result.method_name}_num_features\", len(self.result.selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435484fc-b93d-43b1-8a42-bbe75f7daec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutualInfoSelector(BaseSelector):\n",
    "    \"\"\"Mutual Information feature selector\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        super().__init__(config)\n",
    "        self.k = config[\"feature_selection\"][\"mi\"][\"k\"]\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "        selector = SelectKBest(mutual_info_classif, k=self.k)\n",
    "        selector.fit(X, y.values.ravel())\n",
    "        \n",
    "        self.result = FeatureSelectionResult(\n",
    "            selected_features=X.columns[selector.get_support()],\n",
    "            selection_mask=selector.get_support(),\n",
    "            method_name=\"mi\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18e7e4c-d2d5-41a1-a53d-bdc260ae66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFESelector(BaseSelector):\n",
    "    \"\"\"Recursive Feature Elimination selector\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        super().__init__(config)\n",
    "        self.params = config[\"feature_selection\"][\"rfe\"]\n",
    "        \n",
    "    def _create_estimator(self, y: pd.DataFrame) -> XGBClassifier:\n",
    "        fraud_ratio = y.mean()\n",
    "        return XGBClassifier(\n",
    "            scale_pos_weight=(1 - fraud_ratio) / fraud_ratio,\n",
    "            subsample=self.params[\"subsample\"],\n",
    "            random_state=self.params[\"random_state\"],\n",
    "            device='cuda'\n",
    "        )\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "        estimator = self._create_estimator(y)\n",
    "        selector = RFE(\n",
    "            estimator=estimator,\n",
    "            n_features_to_select=self.params[\"n_features\"],\n",
    "            step=self.params[\"step\"]\n",
    "        )\n",
    "        selector.fit(X, y)\n",
    "        \n",
    "        self.result = FeatureSelectionResult(\n",
    "            selected_features=X.columns[selector.support_],\n",
    "            selection_mask=selector.support_,\n",
    "            method_name=\"rfe\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d15a7f-123d-4c2f-a529-4bdde4948230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapSelector(BaseSelector):\n",
    "    \"\"\"SHAP-based feature selector\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        super().__init__(config)\n",
    "        self.params = config[\"feature_selection\"][\"shap\"]\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "        model = XGBClassifier(\n",
    "            scale_pos_weight=(1 - y.mean()) / y.mean(),\n",
    "            device='cuda'\n",
    "        ).fit(X, y)\n",
    "        \n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        importances = np.abs(shap_values).mean(axis=0)\n",
    "        top_idx = np.argsort(importances)[-self.params[\"n_features\"]:]\n",
    "        \n",
    "        self.result = FeatureSelectionResult(\n",
    "            selected_features=X.columns[top_idx],\n",
    "            selection_mask=np.isin(X.columns, X.columns[top_idx]),\n",
    "            method_name=\"shap\"\n",
    "        )\n",
    "        \n",
    "    def plot_summary(self, shap_values: np.ndarray, features: pd.DataFrame) -> None:\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values, features, show=False)\n",
    "        with TemporaryDirectory() as tmp_dir:\n",
    "            path = Path(tmp_dir) / \"shap_summary.png\"\n",
    "            plt.savefig(path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3c006d-12ab-4bdb-86cf-21663ae605ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureVoter:\n",
    "    \"\"\"Ensemble feature selection voter\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        self.min_votes = config[\"feature_selection\"][\"voting\"][\"min_votes\"]\n",
    "        self.results: List[FeatureSelectionResult] = []\n",
    "        \n",
    "    def add_result(self, result: FeatureSelectionResult) -> None:\n",
    "        self.results.append(result)\n",
    "        \n",
    "    def vote(self) -> FeatureSelectionResult:\n",
    "        selection_matrix = pd.DataFrame(\n",
    "            {r.method_name: r.selection_mask for r in self.results}\n",
    "        )\n",
    "        vote_counts = selection_matrix.sum(axis=1)\n",
    "        \n",
    "        final_mask = vote_counts >= self.min_votes\n",
    "        return FeatureSelectionResult(\n",
    "            selected_features=selection_matrix.index[final_mask],\n",
    "            selection_mask=final_mask.values,\n",
    "            method_name=\"ensemble\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31ad692-09a6-4bb3-86e8-24ab12cc4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelectionArtifacts:\n",
    "    \"\"\"Handles feature selection artifact logging\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        \n",
    "    def log_features(self, features: pd.Index) -> None:\n",
    "        with TemporaryDirectory() as tmp_dir:\n",
    "            path = Path(tmp_dir) / \"selected_features.parquet\"\n",
    "            pd.Series(features).to_frame().to_parquet(path)\n",
    "            mlflow.log_artifact(path, self.config[\"artifacts\"][\"data\"][\"selected\"])\n",
    "            \n",
    "    def log_datasets(self, datasets: Dict[str, pd.DataFrame]) -> None:\n",
    "        with TemporaryDirectory() as tmp_dir:\n",
    "            for i, (split, data) in enumerate(datasets.items()):\n",
    "                path = Path(tmp_dir) / f\"{split}.parquet\"\n",
    "                data.to_parquet(path)\n",
    "                mlflow.log_artifact(\n",
    "                    path, \n",
    "                    f\"{self.config['artifacts']['data']['selected']}/{self.config['dataset']['split_dirs'][i]}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f457bfea-35aa-412d-b0e6-f13ade189dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    \"\"\"Main feature selection pipeline\"\"\"\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.artifacts = FeatureSelectionArtifacts(config)\n",
    "        \n",
    "    def load_data(self) -> None:\n",
    "        \"\"\"Load data from previous pipeline stages\"\"\"\n",
    "        preprocessing_run_id = find_latest_run_id_by_experiment_and_stage(\n",
    "            self.config[\"experiment_names\"][\"preprocessing\"],\n",
    "            self.config[\"run_names\"][\"preprocessing\"]\n",
    "        )\n",
    "        fe_run_id = find_latest_run_id_by_experiment_and_stage(\n",
    "            self.config[\"experiment_names\"][\"feature_engineering\"],\n",
    "            self.config[\"run_names\"][\"feature_engineering\"]\n",
    "        )\n",
    "        \n",
    "        engineered_data = get_data(fe_run_id, self.config[\"dataset\"], self.config[\"artifacts\"][\"data\"][\"engineered\"])\n",
    "        targets = get_targets(preprocessing_run_id, self.config[\"dataset\"], \"processed\")\n",
    "        \n",
    "        self.X_train = engineered_data[\"X_train_enriched\"]\n",
    "        self.y_train = targets[\"y_train\"]\n",
    "        self.X_val = engineered_data[\"X_val_enriched\"]\n",
    "        self.X_test = engineered_data[\"X_test_enriched\"]\n",
    "        \n",
    "    def validate_data(self) -> None:\n",
    "        \"\"\"Validate input data quality\"\"\"\n",
    "        if self.X_train.empty or self.y_train.empty:\n",
    "            raise ValueError(\"Empty training data received\")\n",
    "        if self.X_train.shape[0] != self.y_train.shape[0]:\n",
    "            raise ValueError(\"Feature/target row count mismatch\")\n",
    "\n",
    "    def run_selection(self) -> Tuple[Dict[str, FeatureSelectionResult], FeatureSelectionResult]:\n",
    "        \"\"\"Execute all feature selection methods\"\"\"\n",
    "        selectors = [\n",
    "            MutualInfoSelector(self.config),\n",
    "            RFESelector(self.config),\n",
    "            ShapSelector(self.config)\n",
    "        ]\n",
    "        \n",
    "        individual_results = {}\n",
    "        for selector in selectors:\n",
    "            try:\n",
    "                selector.fit(self.X_train, self.y_train)\n",
    "                selector.log_metrics()\n",
    "                individual_results[selector.result.method_name] = selector.result\n",
    "            except Exception as e:\n",
    "                mlflow.log_param(f\"{selector.__class__.__name__}_error\", str(e))\n",
    "                continue\n",
    "                \n",
    "        voter = FeatureVoter(self.config)\n",
    "        for result in individual_results.values():\n",
    "            voter.add_result(result)\n",
    "            \n",
    "        final_result = voter.vote()\n",
    "        return individual_results, final_result\n",
    "\n",
    "    def log_selection_metrics(self, results: Dict[str, FeatureSelectionResult], final_result: FeatureSelectionResult) -> None:\n",
    "        \"\"\"Log comprehensive selection metrics\"\"\"\n",
    "        mlflow.log_metrics({\n",
    "            \"original_features\": self.X_train.shape[1],\n",
    "            \"final_features_selected\": len(final_result.selected_features),\n",
    "            **{f\"{k}_features\": len(v.selected_features) for k, v in results.items()}\n",
    "        })\n",
    "\n",
    "    def create_selected_datasets(self, final_features: pd.Index) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Create datasets with selected features\"\"\"\n",
    "\n",
    "        # Temporary hack to fix column names; don't do this in production\n",
    "        rename_dict = {old_col: new_col for old_col, new_col in zip(self.X_train.columns, range(len(self.X_train.columns)))}\n",
    "        self.X_train = self.X_train.rename(columns=rename_dict)\n",
    "        self.X_val = self.X_val.rename(columns=rename_dict)\n",
    "        self.X_test = self.X_test.rename(columns=rename_dict)\n",
    "        \n",
    "        return {\n",
    "            \"X_train\": self.X_train[final_features],\n",
    "            \"X_val\": self.X_val[final_features],\n",
    "            \"X_test\": self.X_test[final_features]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a76541e-66cb-4f1c-925c-3506f897ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_pipeline(config: Dict) -> None:\n",
    "    \"\"\"Main feature selection workflow\"\"\"\n",
    "    selector = FeatureSelector(config)\n",
    "    \n",
    "    # Load and validate data\n",
    "    selector.load_data()\n",
    "    selector.validate_data()\n",
    "    \n",
    "    # Run selection methods\n",
    "    individual_results, final_result = selector.run_selection()\n",
    "    \n",
    "    # Log results\n",
    "    selector.log_selection_metrics(individual_results, final_result)\n",
    "    selector.artifacts.log_features(final_result.selected_features)\n",
    "    \n",
    "    # Create and log datasets\n",
    "    selected_data = selector.create_selected_datasets(final_result.selected_features)\n",
    "    selector.artifacts.log_datasets(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca8e9174-3e59-4e5e-a2c0-c8c9364c9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection completed. Run ID: 6c32beccba7345b2997b8f5e3a9ed2dd\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    experiment_name = CONFIG[\"experiment_names\"][\"feature_selection\"]\n",
    "    run_name = CONFIG[\"run_names\"][\"feature_selection\"]\n",
    "    \n",
    "    configure_mlflow(experiment_name)\n",
    "    \n",
    "    try:\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            mlflow.set_tags({\n",
    "                \"stage\": \"feature_selection\",\n",
    "                \"model_type\": \"ensemble_selector\"\n",
    "            })\n",
    "            \n",
    "            # Log lineage and configuration\n",
    "            mlflow.log_dict(CONFIG, \"feature_selection_config.yaml\")\n",
    "            mlflow.log_params({\n",
    "                \"preprocessing_run_id\": find_latest_run_id_by_experiment_and_stage(\n",
    "                    CONFIG[\"experiment_names\"][\"preprocessing\"],\n",
    "                    CONFIG[\"run_names\"][\"preprocessing\"]\n",
    "                ),\n",
    "                \"feature_engineering_run_id\": find_latest_run_id_by_experiment_and_stage(\n",
    "                    CONFIG[\"experiment_names\"][\"feature_engineering\"],\n",
    "                    CONFIG[\"run_names\"][\"feature_engineering\"]\n",
    "                )\n",
    "            })\n",
    "            \n",
    "            feature_selection_pipeline(CONFIG)\n",
    "            mlflow.set_tag(\"status\", \"completed\")\n",
    "            print(f\"Feature selection completed. Run ID: {mlflow.active_run().info.run_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        mlflow.log_param(\"error\", str(e))\n",
    "        mlflow.set_tag(\"status\", \"failed\")\n",
    "        mlflow.end_run()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c25a5a-594a-4e0c-aee2-9f8a6c89d994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
